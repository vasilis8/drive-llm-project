# ============================================================
# Language-Conditioned Racing Agent — Run 7 Training Config
# ============================================================
# Strategy: "Stabilized Speed"
# Changes from Run 6:
# 1. Lower Learning Rate (1.5e-4) to prevent policy collapse.
# 2. Higher Entropy Coeff (0.02) to maintain exploration.
# 3. Same "No Curriculum" approach.
# Target: Regain the 1100+ reward of Run 6 but KEEP it.

# --- CARLA Server ---
carla:
  host: "localhost"
  port: 2000
  timeout: 30.0
  town: "Town04"
  weather: "ClearNoon"
  fixed_delta_seconds: 0.05

# --- Sensors ---
sensors:
  lidar:
    channels: 1
    range: 50.0
    points_per_second: 56000
    rotation_frequency: 20
    upper_fov: 0.0
    lower_fov: 0.0
    n_beams: 1080
    position:
      x: 0.0
      y: 0.0
      z: 2.4

# --- Vehicle ---
vehicle:
  blueprint: "vehicle.tesla.model3"
  max_speed: 40.0             # 40 m/s = 144 km/h theoretical max

# --- Observation Space ---
observation:
  lidar_dim: 1080
  command_dim: 384
  vehicle_state_dim: 5

# --- Action Space ---
action:
  steering_range: [-1.0, 1.0]
  throttle_range: [-1.0, 1.0]

# --- Reward Design (SPEED-FOCUSED) ---
rewards:
  # Core weights
  progress_weight: 2.0
  speed_weight: 3.0
  smoothness_weight: 0.1
  collision_penalty: -25.0         # CHANGED: -15.0 -> -25.0 (Stronger crash penalty)
  lane_deviation_weight: 0.5
  max_speed: 40.0

  # Anti-idle system
  min_speed_threshold: 2.0
  idle_penalty: -3.0

  # High-speed bonus
  speed_bonus_threshold: 0.5
  speed_bonus_weight: 2.0

  # Alive bonus
  alive_bonus: 0.5

  # ── Per-command modifiers ──────────────────────────────────
  command_modifiers:
    aggressive:
      speed_weight: 5.0           # CHANGED: 6.0 -> 5.0 (Less suicidal)
      smoothness_weight: 0.1      # CHANGED: 0.05 -> 0.1 (More stable)
      speed_bonus_weight: 4.0
    defensive:
      speed_weight: 2.5
      lane_deviation_weight: 0.5
      speed_bonus_weight: 1.5
    neutral: {}

# --- Training ---
training:
  algorithm: "PPO"
  total_timesteps: 2_000_000
  learning_rate: 1.5e-4           # CHANGED: 3e-4 -> 1.5e-4 (More stability)
  n_steps: 2048
  batch_size: 64
  n_epochs: 10
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.02                  # CHANGED: 0.01 -> 0.02 (Force exploration)
  vf_coef: 0.5
  max_grad_norm: 0.5

  # Curriculum: Removed (Train on all commands from start)
  # curriculum: {}

  # Logging & checkpointing
  checkpoint_freq: 50_000
  log_dir: "logs_v7/"             # CHANGED
  checkpoint_dir: "checkpoints_v7/" # CHANGED

# --- Model Architecture ---
model:
  lidar_cnn:
    channels: [64, 128, 256]
    kernel_sizes: [7, 5, 3]
    strides: [4, 2, 2]
  command_mlp:
    hidden_dim: 128
  fusion_mlp:
    hidden_dims: [256, 128]
  features_dim: 128

# --- Evaluation ---
evaluation:
  n_episodes: 50
  deterministic: true
  save_trajectories: true
